#!/bin/bash

# Script para configurar una IA local para desarrollo con los mejores modelos de c√≥digo abierto

echo "ü§ñ Configurando IA local para desarrollo..."

# Detectar si el sistema tiene GPU NVIDIA
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ GPU NVIDIA detectada"
    PROFILE="gpu"
else
    echo "‚ö†Ô∏è  No se detect√≥ GPU NVIDIA, usando CPU"
    PROFILE="cpu"
fi

# Levantar los servicios
echo "üê≥ Iniciando servicios Docker..."
docker compose --profile $PROFILE up -d

# Esperar a que Ollama est√© listo
echo "‚è≥ Esperando a que Ollama est√© listo..."
sleep 10

# Descargar los mejores modelos de c√≥digo abierto para desarrollo
echo "üì• Descargando modelos de IA para desarrollo..."

# CodeLlama 34B - Excelente para c√≥digo
echo "Descargando CodeLlama 34B (especializado en c√≥digo)..."
docker exec ollama-dev-ai-${PROFILE} ollama pull codellama:34b

# Llama 3.1 8B - Muy bueno y r√°pido
echo "Descargando Llama 3.1 8B (r√°pido y eficiente)..."
docker exec ollama-dev-ai-${PROFILE} ollama pull llama3.1:8b

# DeepSeek Coder 33B - Especializado en programaci√≥n
echo "Descargando DeepSeek Coder 33B (especialista en c√≥digo)..."
docker exec ollama-dev-ai-${PROFILE} ollama pull deepseek-coder:33b

# Qwen 2.5 Coder 32B - Uno de los mejores para c√≥digo
echo "Descargando Qwen 2.5 Coder 32B (excelente para c√≥digo)..."
docker exec ollama-dev-ai-${PROFILE} ollama pull qwen2.5-coder:32b

# Granite Code 34B - Modelo de IBM para c√≥digo
echo "Descargando Granite Code 34B (modelo de IBM)..."
docker exec ollama-dev-ai-${PROFILE} ollama pull granite-code:34b

# Establecer modelo por defecto
echo "üéØ Configurando modelo por defecto..."
docker exec ollama-dev-ai-${PROFILE} ollama pull qwen2.5-coder:7b

echo "‚úÖ ¬°Configuraci√≥n completada!"
echo ""
echo "üîó URLs disponibles:"
echo "   ‚Ä¢ Ollama API: http://localhost:11434"
echo "   ‚Ä¢ Web UI: http://localhost:3000"
echo ""
echo "üìù Modelos instalados:"
echo "   ‚Ä¢ qwen2.5-coder:32b (recomendado para c√≥digo complejo)"
echo "   ‚Ä¢ qwen2.5-coder:7b (r√°pido para c√≥digo simple)"
echo "   ‚Ä¢ codellama:34b (especialista en c√≥digo)"
echo "   ‚Ä¢ llama3.1:8b (uso general r√°pido)"
echo "   ‚Ä¢ deepseek-coder:33b (experto en programaci√≥n)"
echo "   ‚Ä¢ granite-code:34b (modelo IBM para c√≥digo)"
echo ""
echo "üõ†Ô∏è  Para usar en VS Code, instala la extensi√≥n 'Continue' y config√∫rala con:"
echo "   URL: http://localhost:11434"
echo "   Modelo recomendado: qwen2.5-coder:7b"
